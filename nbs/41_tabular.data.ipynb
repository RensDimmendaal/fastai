{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#| eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp tabular.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.tabular.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular data\n",
    "\n",
    "> Helper functions to get data in a `DataLoaders` in the tabular application and higher class `TabularDataLoaders`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main class to get your data ready for model training is `TabularDataLoaders` and its factory methods. Checkout the [tabular tutorial](http://docs.fast.ai/tutorial.tabular.html) for examples of use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabularDataLoaders -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TabularDataLoaders(DataLoaders):\n",
    "    \"Basic wrapper around several `DataLoader`s with factory methods for tabular data\"\n",
    "    @classmethod\n",
    "    @delegates(Tabular.dataloaders, but=[\"dl_type\", \"dl_kwargs\"])\n",
    "    def from_df(cls, \n",
    "        df:pd.DataFrame,\n",
    "        path:str|Path='.', # Location of `df`, defaults to current working directory\n",
    "        procs:list=None, # List of `TabularProc`s\n",
    "        cat_names:list=None, # Column names pertaining to categorical variables\n",
    "        cont_names:list=None, # Column names pertaining to continuous variables\n",
    "        y_names:list=None, # Names of the dependent variables\n",
    "        y_block:TransformBlock=None, # `TransformBlock` to use for the target(s)\n",
    "        valid_idx:list=None, # List of indices to use for the validation set, defaults to a random split\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"Create `TabularDataLoaders` from `df` in `path` using `procs`\"\n",
    "        if cat_names is None: cat_names = []\n",
    "        if cont_names is None: cont_names = list(set(df)-set(L(cat_names))-set(L(y_names)))\n",
    "        splits = RandomSplitter()(df) if valid_idx is None else IndexSplitter(valid_idx)(df)\n",
    "        to = TabularPandas(df, procs, cat_names, cont_names, y_names, splits=splits, y_block=y_block)\n",
    "        return to.dataloaders(path=path, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def from_csv(cls, \n",
    "        csv:str|Path|io.BufferedReader, # A csv of training data\n",
    "        skipinitialspace:bool=True, # Skip spaces after delimiter\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"Create `TabularDataLoaders` from `csv` file in `path` using `procs`\"\n",
    "        return cls.from_df(pd.read_csv(csv, skipinitialspace=skipinitialspace), **kwargs)\n",
    "\n",
    "    @delegates(TabDataLoader.__init__)\n",
    "    def test_dl(self, \n",
    "        test_items, # Items to create new test `TabDataLoader` formatted the same as the training data\n",
    "        rm_type_tfms=None, # Number of `Transform`s to be removed from `procs`\n",
    "        process:bool=True, # Apply validation `TabularProc`s to `test_items` immediately\n",
    "        inplace:bool=False, # Keep separate copy of original `test_items` in memory if `False`\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"Create test `TabDataLoader` from `test_items` using validation `procs`\"\n",
    "        to = self.train_ds.new(test_items, inplace=inplace)\n",
    "        if process: to.process()\n",
    "        return self.valid.new(to, **kwargs)\n",
    "\n",
    "Tabular._dbunch_type = TabularDataLoaders\n",
    "TabularDataLoaders.from_csv = delegates(to=TabularDataLoaders.from_df)(TabularDataLoaders.from_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class should not be used directly, one of the factory methods should be preferred instead. All those factory methods accept as arguments:\n",
    "\n",
    "- `cat_names`: the names of the categorical variables\n",
    "- `cont_names`: the names of the continuous variables\n",
    "- `y_names`: the names of the dependent variables\n",
    "- `y_block`: the `TransformBlock` to use for the target\n",
    "- `valid_idx`: the indices to use for the validation set (defaults to a random split otherwise)\n",
    "- `bs`: the batch size\n",
    "- `val_bs`: the batch size for the validation `DataLoader` (defaults to `bs`)\n",
    "- `shuffle_train`: if we shuffle the training `DataLoader` or not\n",
    "- `n`: overrides the numbers of elements in the dataset\n",
    "- `device`: the PyTorch device to use (defaults to `default_device()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TabularDataLoaders.from_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on an example with the adult dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv', skipinitialspace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = TabularDataLoaders.from_df(df, path, procs=procs, cat_names=cat_names, cont_names=cont_names, \n",
    "                                 y_names=\"salary\", valid_idx=list(range(800,1000)), bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TabularDataLoaders.from_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, procs=procs, cat_names=cat_names, cont_names=cont_names, \n",
    "                                  y_names=\"salary\", valid_idx=list(range(800,1000)), bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TabularDataLoaders.test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External structured data files can contain unexpected spaces, e.g. after a comma. We can see that in the first row of adult.csv `\"49, Private,101320, ...\"`. Often trimming is needed. Pandas has a convenient parameter `skipinitialspace` that is exposed by `TabularDataLoaders.from_csv()`. Otherwise category labels use for inference later such as `workclass`:`Private` will be categorized wrongly to *0* or `\"#na#\"` if training label was read as `\" Private\"`. Let's test this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {\n",
    "    'age': [49], \n",
    "    'workclass': ['Private'], \n",
    "    'fnlwgt': [101320],\n",
    "    'education': ['Assoc-acdm'], \n",
    "    'education-num': [12.0],\n",
    "    'marital-status': ['Married-civ-spouse'], \n",
    "    'occupation': [''],\n",
    "    'relationship': ['Wife'],\n",
    "    'race': ['White'],\n",
    "}\n",
    "input = pd.DataFrame(test_data)\n",
    "tdl = dls.test_dl(input)\n",
    "\n",
    "test_ne(0, tdl.dataset.iloc[0]['workclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

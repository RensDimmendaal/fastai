{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#| eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp vision.rect_augment\n",
    "#|default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rectangular computer vision augmentation\n",
    "\n",
    "> Transforms to apply data augmentation to rectangular images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from fastai.core.imports import *\n",
    "from fastai.test import *\n",
    "from fastai.core import *\n",
    "from fastai.data.transform import *\n",
    "from fastai.data.pipeline import *\n",
    "from fastai.data.source import *\n",
    "from fastai.data.core import *\n",
    "from fastai.vision.core import *\n",
    "from fastai.vision.augment import *\n",
    "from fastai.data.external import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import showdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SortARSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- resize large images\n",
    "- sort by size (size group of size n=1000//bs\\*bs) and AR\n",
    "- shufflish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "items = get_image_files(path/'images')\n",
    "labeller = RegexLabeller(pat = r'/([^/]+)_\\d+.jpg$')\n",
    "split_idx = RandomSplitter()(items)\n",
    "tfms = [PILImage.create, [labeller, Categorize()]]\n",
    "tds = TfmdDS(items, tfms)\n",
    "im = tds[0][0]; im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SortARSampler(BatchSampler):\n",
    "    def __init__(self, ds, items=None, bs=32, grp_sz=1000, shuffle=False, drop_last=False):\n",
    "        if not items: items=ds.items\n",
    "        self.shapes = [Image.open(it).shape for it in items]\n",
    "        self.sizes = [h*w for h,w in self.shapes]\n",
    "        self.ars = [h/w for h,w in self.shapes]\n",
    "        self.ds,self.grp_sz,self.bs,self.shuffle,self.drop_last = ds,round_multiple(grp_sz,bs),bs,shuffle,drop_last\n",
    "        self.grp_sz = round_multiple(grp_sz,bs)\n",
    "        \n",
    "        # reverse argsort of sizes\n",
    "        idxs = [i for i,o in sorted(enumerate(self.sizes), key=itemgetter(1), reverse=True)]\n",
    "        # create approx equal sized groups no larger than `grp_sz`\n",
    "        grps = [idxs[i:i+self.grp_sz] for i in range(0, len(idxs), self.grp_sz)]\n",
    "        # sort within groups by aspect ratio\n",
    "        self.grps = [sorted(g, key=lambda o:self.ars[o]) for g in grps]\n",
    "\n",
    "    def __iter__(self):\n",
    "        grps = self.grps\n",
    "        if self.shuffle: grps = [shufflish(o) for o in grps]\n",
    "        grps = [g[i:i+self.bs] for g in grps for i in range(0, len(g), self.bs)]\n",
    "        if self.drop_last and len(grps[-1])!=self.bs: del(grps[-1])\n",
    "        # Shuffle all but first (so can have largest first)\n",
    "        if self.shuffle: grps = random.sample(grps[1:], len(grps)-1) + [grps[0]]\n",
    "        return iter(grps)\n",
    "\n",
    "    def __len__(self): return (len(self.ds) if self.drop_last else (len(self.ds)+self.bs-1)) // self.bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = SortARSampler(tds, shuffle=False)\n",
    "test_eq(len(samp), (len(tds)-1)//32+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = iter(samp)\n",
    "first = next(itr)\n",
    "i = 1\n",
    "for last in itr: i += 1\n",
    "test_eq(len(samp), i)\n",
    "first = [tds[i][0] for i in first]\n",
    "last  = [tds[i][0] for i in last]\n",
    "#big images are first, smaller images last\n",
    "assert np.mean([im.n_px for im in last])*5 < np.mean([im.n_px for im in first])\n",
    "#Higher aspect ratios are first\n",
    "assert np.mean([im.aspect for im in last])*2 < np.mean([im.aspect for im in first])\n",
    "#In a batch with similar aspect ratio\n",
    "assert np.std([im.aspect for im in first]) < 0.1\n",
    "assert np.std([im.aspect for im in last]) < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = SortARSampler(tds, shuffle=True)\n",
    "itr = iter(samp)\n",
    "first = next(itr)\n",
    "for last in itr: pass\n",
    "first = [tds[i][0] for i in first]\n",
    "last  = [tds[i][0] for i in last]\n",
    "#In a batch with similar aspect ratio\n",
    "assert np.std([im.aspect for im in first]) < 0.1\n",
    "assert np.std([im.aspect for im in last]) < 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResizeCollate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ResizeCollate(TfmdCollate):\n",
    "    def __init__(self, tfms=None, collate_fn=default_collate, sz=None, is_fixed_px=False, max_px=512*512, round_mult=None,\n",
    "                rand_min_scale=None, rand_ratio_pct=None): \n",
    "        super().__init__(tfms, collate_fn)\n",
    "        self.round_mult,self.is_fixed_px,self.max_px = round_mult,is_fixed_px,max_px\n",
    "        self.is_rand = rand_min_scale or rand_ratio_pct\n",
    "        if self.is_rand:\n",
    "            self.inv_ratio = 1-ifnone(rand_ratio_pct, 0.10)\n",
    "            self.resize = RandomResizedCrop(1, min_scale=ifnone(rand_min_scale, 0.25), as_item=False)\n",
    "        else: self.resize = Resize(1, as_item=False)\n",
    "        self.sz = None if sz is None else (sz, sz) if isinstance(sz, int) else sz\n",
    "        \n",
    "    def __call__(self, samples):\n",
    "        if self.sz is None:\n",
    "            if self.is_fixed_px: px = self.max_px\n",
    "            else: px = min(self.max_px, max(L(o[0].shape[0]*o[0].shape[1] for o in samples)))\n",
    "            ar = np.median(L(o[0].aspect for o in samples))\n",
    "            sz = int(math.sqrt(px*ar)),int(math.sqrt(px/ar))\n",
    "        else: sz,ar = self.sz,self.sz[1]/self.sz[0]\n",
    "        if self.round_mult is not None: sz = round_multiple(sz, self.round_mult, round_down=True)\n",
    "        if self.is_rand: self.resize.ratio = (ar*self.inv_ratio, ar/self.inv_ratio)\n",
    "        return super().__call__(self.resize(o,size=sz) for o in samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = SortARSampler(tds, shuffle=True, bs=16)\n",
    "collate_fn = ResizeCollate(max_px=10000)\n",
    "tdl = TfmdDL(tds, batch_sampler=samp, collate_fn=collate_fn, num_workers=0)\n",
    "batch = tdl.one_batch()\n",
    "\n",
    "test_eq(L(batch).map(type), (TensorImage,Tensor))\n",
    "b,c,h,w = batch[0].shape\n",
    "assert 9000<h*w<=10000\n",
    "test_eq(b, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = ResizeCollate(is_fixed_px=True, max_px=500000)\n",
    "tdl = TfmdDL(tds, batch_sampler=samp, collate_fn=collate_fn, num_workers=0)\n",
    "batch = tdl.one_batch()\n",
    "b,c,h,w = batch[0].shape\n",
    "assert 490000<h*w<=500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = ResizeCollate(sz=128)\n",
    "tdl = TfmdDL(tds, batch_sampler=samp, collate_fn=collate_fn, num_workers=0)\n",
    "batch = tdl.one_batch()\n",
    "test_eq(batch[0].shape[2:], [128,128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = ResizeCollate(round_mult=32, max_px=10000)\n",
    "tdl = TfmdDL(tds, batch_sampler=samp, collate_fn=collate_fn, num_workers=0)\n",
    "batch = tdl.one_batch()\n",
    "b,c,h,w = batch[0].shape\n",
    "test_eq(h%32, 0)\n",
    "test_eq(w%32, 0)\n",
    "assert h*w<=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = ResizeCollate(sz=128, rand_min_scale=0.7)\n",
    "tdl = TfmdDL(tds, batch_sampler=samp, collate_fn=collate_fn, num_workers=0)\n",
    "_,axs = plt.subplots(3,3, figsize=(9,9))\n",
    "tdl.show_batch(ctxs=axs.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = ResizeCollate(rand_min_scale=0.25, rand_ratio_pct=0.3)\n",
    "tdl = TfmdDL(tds, batch_sampler=samp, collate_fn=collate_fn, num_workers=0)\n",
    "_,axs = plt.subplots(3,3, figsize=(9,9))\n",
    "tdl.show_batch(ctxs=axs.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On object detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_pad_collate(samples, pad_idx=0):\n",
    "    \"Function that collect `samples` of labelled bboxes and adds padding with `pad_idx`.\"\n",
    "    if isinstance(samples[0][1], int): return data_collate(samples)\n",
    "    max_len = max([len(s[1][1]) for s in samples])\n",
    "    bboxes = torch.zeros(len(samples), max_len, 4)\n",
    "    labels = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    imgs = []\n",
    "    for i,s in enumerate(samples):\n",
    "        imgs.append(s[0][None])\n",
    "        bbs, lbls = s[1]\n",
    "        if not (bbs.nelement() == 0):\n",
    "            bboxes[i,-len(lbls):] = bbs\n",
    "            labels[i,-len(lbls):] = tensor(lbls)\n",
    "    return torch.cat(imgs,0), (bboxes,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PASCAL_2007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, lbl_bbox = get_annotations(path/'train.json')\n",
    "img2bbox = dict(zip(images, lbl_bbox))\n",
    "_pascal_lbl = lambda o: BBox.create(img2bbox[o.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [path/'train'/fn for fn in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_tds = TfmdDS(items, [PILImage.create, [_pascal_lbl, BBoxCategorize()]], item_tfms=[BBoxScaler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_tds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = ResizeCollate(rand_min_scale=0.25, rand_ratio_pct=0.3, collate_fn=bb_pad_collate)\n",
    "tdl = TfmdDL(pascal_tds, batch_sampler=samp, collate_fn=collate_fn, num_workers=0)\n",
    "_,axs = plt.subplots(3,3, figsize=(9,9))\n",
    "tdl.show_batch(ctxs=axs.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rect training (not working well)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a rectangular training, we change the dataset transforms to use the flip only. We will resize the images when it's time to batch them only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_tfms = [FlipItem(0.5)]\n",
    "#tfms = [PILImage.create, [parent_label, Categorize()]]\n",
    "#dsets = Datasets(items, tfms, splits=split_idx, item_tfms=img_tfms)\n",
    "\n",
    "#tfms = [Cuda(), IntToFloatTensor(), Normalize(*imagenet_stats)]\n",
    "#bs = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a sampler that will group the images by batches of the close size and aspect ratio (with a bit of shuffle for the training set) and a collation function that will resize them to the mdeian aspect ratio and median number of pixel (bound by `max_px`). `rand_min_scale` is used to do a `RandomResizedCrop` to that size on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samp = SortARSampler(dsets.train, shuffle=True, bs=bs)\n",
    "#collate_fn = ResizeCollate(max_px=128*128, rand_min_scale=0.35, rand_ratio_pct=0.33, round_mult=32)\n",
    "#train_dl = TfmdDL(dsets.train, tfms, num_workers=8, batch_sampler=samp, collate_fn=collate_fn)\n",
    "\n",
    "#samp = SortARSampler(dsets.valid, shuffle=False, bs=bs)\n",
    "#collate_fn = ResizeCollate(max_px=128*128, round_mult=32)\n",
    "#valid_dl = TfmdDL(dsets.valid, tfms, num_workers=8, batch_sampler=samp, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a `DataLoaders` with those two dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dls1 = imagenette.dataloaders(source, bs=64, num_workers=8, item_tfms=item_img_tfms, batch_tfms=Normalize(*imagenet_stats))\n",
    "\n",
    "#dls = DataLoaders(train_dl, valid_dl)\n",
    "#dls.show_batch(max_n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn = vision_learner(xresnet18, dls, LabelSmoothingCrossEntropy(), opt_func=opt_func, c_in=3, c_out=10, lr=1e-2, metrics=accuracy)\n",
    "#learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

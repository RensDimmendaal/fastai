{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#| eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp medical.imaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Imaging\n",
    "\n",
    "> Helpers for working with DICOM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "from __future__ import annotations\n",
    "from fastai.basics import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.data.transforms import *\n",
    "\n",
    "import pydicom,kornia,skimage\n",
    "from pydicom.dataset import Dataset as DcmDataset\n",
    "from pydicom.tag import BaseTag as DcmTag\n",
    "from pydicom.multival import MultiValue as DcmMultiValue\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "    cv2.setNumThreads(0)\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "matplotlib.rcParams['image.cmap'] = 'bone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "_all_ = ['DcmDataset', 'DcmTag', 'DcmMultiValue', 'dcmread', 'get_dicom_files', 'DicomSegmentationDataLoaders']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_dicom_files(path, recurse=True, folders=None):\n",
    "    \"Get dicom files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=[\".dcm\",\".dicom\"], recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def dcmread(fn:Path, force = False):\n",
    "    \"Open a `DICOM` file\"\n",
    "    return pydicom.dcmread(str(fn), force)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fastai.medical.imaging` uses `pydicom.dcmread` to read a DICOM file. To view the `header` of a DICOM, specify the `path` of a test file and call `dcmread`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DCM = Path('images/sample.dcm')\n",
    "dcm = TEST_DCM.dcmread()\n",
    "dcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TensorDicom(TensorImage):\n",
    "    \"Inherits from `TensorImage` and converts the `pixel_array` into a `TensorDicom`\"\n",
    "    _show_args = {'cmap':'gray'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class PILDicom(PILBase):\n",
    "    _open_args,_tensor_cls,_show_args = {},TensorDicom,TensorDicom._show_args\n",
    "    @classmethod\n",
    "    def create(cls, fn:Path|str|bytes, mode=None)->None:\n",
    "        \"Open a `DICOM file` from path `fn` or bytes `fn` and load it as a `PIL Image`\"\n",
    "        if isinstance(fn,bytes): im = Image.fromarray(pydicom.dcmread(pydicom.filebase.DicomBytesIO(fn)).pixel_array)\n",
    "        if isinstance(fn,(Path,str)): im = Image.fromarray(pydicom.dcmread(fn).pixel_array)\n",
    "        im.load()\n",
    "        im = im._new(im.im)\n",
    "        return cls(im.convert(mode) if mode else im)\n",
    "\n",
    "PILDicom._tensor_cls = TensorDicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def png16read(self:Path): return array(Image.open(self), dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch(as_prop=True)\n",
    "def pixels(self:DcmDataset):\n",
    "    \"`pixel_array` as a tensor\"\n",
    "    return tensor(self.pixel_array.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm.pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch(as_prop=True)\n",
    "def scaled_px(self:DcmDataset):\n",
    "    \"`pixels` scaled by `RescaleSlope` and `RescaleIntercept`\"\n",
    "    img = self.pixels\n",
    "    if hasattr(self, 'RescaleSlope') and hasattr(self, 'RescaleIntercept') is not None:\n",
    "        return img * self.RescaleSlope + self.RescaleIntercept \n",
    "    else: return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scaled_px` uses `RescaleSlope` and `RescaleIntercept` values to correctly scale the image so that they represent the correct tissue densities. You can observe what `scaled_px` does by viewing the the pixel distribution of a dicom image.  The histogram below displays the current pixel distribution which shows a pixel range between `-1133` and `2545`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dcm.pixels.flatten().numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the `header` of the test image the `RescaleIntercept` has a value of `-1024.0` and a `RescaleSlope` value of `1.0`. `scaled_px` will scale the pixels by these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dcm.scaled_px.flatten().numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel distibution is now between `-2157` and `1521`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def array_freqhist_bins(self, n_bins=100):\n",
    "    \"A numpy based function to split the range of pixel values into groups, such that each group has around the same number of pixels\"\n",
    "    imsd = np.sort(self.flatten())\n",
    "    t = np.array([0.001])\n",
    "    t = np.append(t, np.arange(n_bins)/n_bins+(1/2/n_bins))\n",
    "    t = np.append(t, 0.999)\n",
    "    t = (len(imsd)*t+0.5).astype(int)\n",
    "    return np.unique(imsd[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def freqhist_bins(self:Tensor, n_bins=100):\n",
    "    \"A function to split the range of pixel values into groups, such that each group has around the same number of pixels\"\n",
    "    imsd = self.view(-1).sort()[0]\n",
    "    t = torch.cat([tensor([0.001]),\n",
    "                   torch.arange(n_bins).float()/n_bins+(1/2/n_bins),\n",
    "                   tensor([0.999])])\n",
    "    t = (len(imsd)*t).long()\n",
    "    return imsd[t].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example with `n_bins` set to `1` this means the bins will be split into 3 distinct bins (the beginning, the end and the number of bins specified by `n_bins`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_bin = dcm.pixels.freqhist_bins(n_bins=1)\n",
    "t_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(t_bin.numpy(), bins=t_bin, color='c')\n",
    "plt.plot(t_bin, torch.linspace(0,1,len(t_bin)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with `n_bins` at 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_bin = dcm.pixels.freqhist_bins(n_bins=100)\n",
    "t_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(t_bin.numpy(), bins=t_bin, color='c'); plt.plot(t_bin, torch.linspace(0,1,len(t_bin)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def hist_scaled_pt(self:Tensor, brks=None):\n",
    "    # Pytorch-only version - switch to this if/when interp_1d can be optimized\n",
    "    if brks is None: brks = self.freqhist_bins()\n",
    "    brks = brks.to(self.device)\n",
    "    ys = torch.linspace(0., 1., len(brks)).to(self.device)\n",
    "    return self.flatten().interp_1d(brks, ys).reshape(self.shape).clamp(0.,1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def hist_scaled(self:Tensor, brks=None):\n",
    "    \"Scales a tensor using `freqhist_bins` to values between 0 and 1\"\n",
    "    if self.device.type=='cuda': return self.hist_scaled_pt(brks)\n",
    "    if brks is None: brks = self.freqhist_bins()\n",
    "    ys = np.linspace(0., 1., len(brks))\n",
    "    x = self.numpy().flatten()\n",
    "    x = np.interp(x, brks.numpy(), ys)\n",
    "    return tensor(x).reshape(self.shape).clamp(0.,1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test image has pixel values that range between `-1000` and `2500`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dcm.pixels.flatten().numpy(), bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hist_scaled` provides a way of scaling the input pixel values to between `0` and `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_hists = dcm.pixels.hist_scaled()\n",
    "plt.hist(tensor_hists.flatten().numpy(), bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def hist_scaled(self:DcmDataset, brks=None, min_px=None, max_px=None):\n",
    "    \"Pixels scaled to a `min_px` and `max_px` value\"\n",
    "    px = self.scaled_px\n",
    "    if min_px is not None: px[px<min_px] = min_px\n",
    "    if max_px is not None: px[px>max_px] = max_px\n",
    "    return px.hist_scaled(brks=brks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = dcm.hist_scaled()\n",
    "plt.imshow(data_scaled, cmap=plt.cm.bone);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = dcm.hist_scaled(min_px=100, max_px=1000)\n",
    "plt.imshow(data_scaled, cmap=plt.cm.bone);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicom images can contain a high amount of voxel values and windowing can be thought of as a means of manipulating these values in order to change the apperance of the image so particular structures are highlighted. A window has 2 values:\n",
    "\n",
    "- `l` = window level or center aka brightness\n",
    "- `w` = window width or range aka contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def windowed(self:Tensor, w, l):\n",
    "    \"Scale pixel intensity by window width and window level\"\n",
    "    px = self.clone()\n",
    "    px_min = l - w//2\n",
    "    px_max = l + w//2\n",
    "    px[px<px_min] = px_min\n",
    "    px[px>px_max] = px_max\n",
    "    return (px-px_min) / (px_max-px_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def windowed(self:DcmDataset, w, l):\n",
    "    return self.scaled_px.windowed(w,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# From https://radiopaedia.org/articles/windowing-ct\n",
    "dicom_windows = types.SimpleNamespace(\n",
    "    brain=(80,40),\n",
    "    subdural=(254,100),\n",
    "    stroke=(8,32),\n",
    "    brain_bone=(2800,600),\n",
    "    brain_soft=(375,40),\n",
    "    lungs=(1500,-600),\n",
    "    mediastinum=(350,50),\n",
    "    abdomen_soft=(400,50),\n",
    "    liver=(150,30),\n",
    "    spine_soft=(250,50),\n",
    "    spine_bone=(1800,400)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dcm.windowed(*dicom_windows.brain), cmap=plt.cm.bone);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TensorCTScan(TensorImageBW): \n",
    "    \"Inherits from `TensorImageBW` and converts the `pixel_array` into a `TensorCTScan`\"\n",
    "    _show_args = {'cmap':'bone'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_ct = TensorCTScan(dcm.pixel_array)\n",
    "tensor_ct.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class PILCTScan(PILBase): _open_args,_tensor_cls,_show_args = {},TensorCTScan,TensorCTScan._show_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "@delegates(show_image)\n",
    "def show(self:DcmDataset, scale=True, cmap=plt.cm.bone, min_px=-1100, max_px=None, **kwargs):\n",
    "    \"Display a normalized dicom image by default\"\n",
    "    px = (self.windowed(*scale) if isinstance(scale,tuple)\n",
    "          else self.hist_scaled(min_px=min_px,max_px=max_px,brks=scale) if isinstance(scale,(ndarray,Tensor))\n",
    "          else self.hist_scaled(min_px=min_px,max_px=max_px) if scale\n",
    "          else self.scaled_px)\n",
    "    show_image(px, cmap=cmap, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = False, True, dicom_windows.brain, dicom_windows.subdural\n",
    "titles = 'raw','normalized','brain windowed','subdural windowed'\n",
    "for s,a,t in zip(scales, subplots(2,2,imsize=4)[1].flat, titles):\n",
    "    dcm.show(scale=s, ax=a, title=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm.show(cmap=plt.cm.gist_ncar, figsize=(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dicom datasets such as the [The Thyroid Segmentation in Ultrasonography Dataset](https://opencas.webarchiv.kit.edu/?q=node/29) is a dataset where each image has multiple frames per file (hundreds in this case). By default the `show` function will display 1 frame but if the dataset has multiple frames you can specify the number of frames to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def show(self:DcmDataset, frames=1, scale=True, cmap=plt.cm.bone, min_px=-1100, max_px=None, **kwargs):\n",
    "    \"Adds functionality to view dicom images where each file may have more than 1 frame\"\n",
    "    px = (self.windowed(*scale) if isinstance(scale,tuple)\n",
    "          else self.hist_scaled(min_px=min_px,max_px=max_px,brks=scale) if isinstance(scale,(ndarray,Tensor))\n",
    "          else self.hist_scaled(min_px=min_px,max_px=max_px) if scale\n",
    "          else self.scaled_px)\n",
    "    if px.ndim > 2:\n",
    "        gh=[]\n",
    "        p = px.shape; print(f'{p[0]} frames per file')\n",
    "        for i in range(frames): u = px[i]; gh.append(u)\n",
    "        show_images(gh, **kwargs)\n",
    "    else: show_image(px, cmap=cmap, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def pct_in_window(dcm:DcmDataset, w, l):\n",
    "    \"% of pixels in the window `(w,l)`\"\n",
    "    px = dcm.scaled_px\n",
    "    return ((px > l-w//2) & (px < l+w//2)).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm.pct_in_window(*dicom_windows.brain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pct_in_window` can be used to check what percentage of the image is composed of meaningful pixels (pixels within the specified window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def uniform_blur2d(x,s):\n",
    "    \"Uniformly apply blurring\"\n",
    "    w = x.new_ones(1,1,1,s)/s\n",
    "    # Factor 2d conv into 2 1d convs\n",
    "    x = unsqueeze(x, dim=0, n=4-x.dim())\n",
    "    r = (F.conv2d(x, w, padding=s//2))\n",
    "    r = (F.conv2d(r, w.transpose(-1,-2), padding=s//2)).cpu()[:,0]\n",
    "    return r.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = dcm.hist_scaled(), uniform_blur2d(dcm.hist_scaled(), 20), uniform_blur2d(dcm.hist_scaled(), 50)\n",
    "show_images(ims, titles=('original', 'blurred 20', 'blurred 50'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def gauss_blur2d(x,s):\n",
    "    \"Apply gaussian_blur2d kornia filter\"\n",
    "    s2 = int(s/4)*2+1\n",
    "    x2 = unsqueeze(x, dim=0, n=4-x.dim())\n",
    "    res = kornia.filters.gaussian_blur2d(x2, (s2,s2), (s,s), 'replicate')\n",
    "    return res.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = dcm.hist_scaled(), gauss_blur2d(dcm.hist_scaled(), 20), gauss_blur2d(dcm.hist_scaled(), 50)\n",
    "show_images(ims, titles=('original', 'gauss_blur 20', 'gauss_blur 50'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are often affected by random variations in intensity values, called noise. Gaussian noise contains variatons in intensity that are drawn from a Gaussian or normal distribution.  A Guassian filter is usually used to blur edges and remove smaller or thinner areas  in order to preserve the most important information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def mask_from_blur(x:Tensor, window, sigma=0.3, thresh=0.05, remove_max=True):\n",
    "    \"Create a mask from the blurred image\"\n",
    "    p = x.windowed(*window)\n",
    "    if remove_max: p[p==1] = 0\n",
    "    return gauss_blur2d(p, s=sigma*x.shape[-1])>thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def mask_from_blur(x:DcmDataset, window, sigma=0.3, thresh=0.05, remove_max=True):\n",
    "    \"Create a mask from the blurred image\"\n",
    "    return to_device(x.scaled_px).mask_from_blur(window, sigma, thresh, remove_max=remove_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = dcm.mask_from_blur(dicom_windows.brain, sigma=0.9, thresh=0.1, remove_max=True)\n",
    "wind = dcm.windowed(*dicom_windows.brain)\n",
    "\n",
    "_,ax = subplots(1,3)\n",
    "show_image(wind, ax=ax[0], title='window')\n",
    "show_image(mask, alpha=0.5, cmap=plt.cm.Reds, ax=ax[1], title='mask')\n",
    "show_image(wind, ax=ax[2])\n",
    "show_image(mask, alpha=0.5, cmap=plt.cm.Reds, ax=ax[2], title='window and mask');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _px_bounds(x, dim):\n",
    "    c = x.sum(dim).nonzero().cpu()\n",
    "    idxs,vals = torch.unique(c[:,0],return_counts=True)\n",
    "    vs = torch.split_with_sizes(c[:,1],tuple(vals))\n",
    "    d = {k.item():v for k,v in zip(idxs,vs)}\n",
    "    default_u = tensor([0,x.shape[-1]-1])\n",
    "    b = [d.get(o,default_u) for o in range(x.shape[0])]\n",
    "    b = [tensor([o.min(),o.max()]) for o in b]\n",
    "    return torch.stack(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def mask2bbox(mask):\n",
    "    no_batch = mask.dim()==2\n",
    "    if no_batch: mask = mask[None]\n",
    "    bb1 = _px_bounds(mask,-1).t()\n",
    "    bb2 = _px_bounds(mask,-2).t()\n",
    "    res = torch.stack([bb1,bb2],dim=1).to(mask.device)\n",
    "    return res[...,0] if no_batch else res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbs = mask2bbox(mask)\n",
    "lo,hi = bbs\n",
    "show_image(wind[lo[0]:hi[0],lo[1]:hi[1]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _bbs2sizes(crops, init_sz, use_square=True):\n",
    "    bb = crops.flip(1)\n",
    "    szs = (bb[1]-bb[0])\n",
    "    if use_square: szs = szs.max(0)[0][None].repeat((2,1))\n",
    "    overs = (szs+bb[0])>init_sz\n",
    "    bb[0][overs] = init_sz-szs[overs]\n",
    "    lows = (bb[0]/float(init_sz))\n",
    "    return lows,szs/float(init_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def crop_resize(x, crops, new_sz):\n",
    "    # NB assumes square inputs. Not tested for non-square anythings!\n",
    "    bs = x.shape[0]\n",
    "    lows,szs = _bbs2sizes(crops, x.shape[-1])\n",
    "    if not isinstance(new_sz,(list,tuple)): new_sz = (new_sz,new_sz)\n",
    "    id_mat = tensor([[1.,0,0],[0,1,0]])[None].repeat((bs,1,1)).to(x.device)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        sp = F.affine_grid(id_mat, (bs,1,*new_sz))+1.\n",
    "        grid = sp*unsqueeze(szs.t(),1,n=2)+unsqueeze(lows.t()*2.,1,n=2)\n",
    "        return F.grid_sample(x.unsqueeze(1), grid-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px256 = crop_resize(to_device(wind[None]), bbs[...,None], 128)[0]\n",
    "show_image(px256)\n",
    "px256.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the original image with the image from using the `mask` and `crop_resize` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axs = subplots(1,2)\n",
    "dcm.show(ax=axs[0])\n",
    "show_image(px256, ax=axs[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def to_nchan(x:Tensor, wins, bins=None):\n",
    "    res = [x.windowed(*win) for win in wins]\n",
    "    if not isinstance(bins,int) or bins!=0: res.append(x.hist_scaled(bins).clamp(0,1))\n",
    "    dim = [0,1][x.dim()==3]\n",
    "    return TensorCTScan(torch.stack(res, dim=dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def to_nchan(x:DcmDataset, wins, bins=None):\n",
    "    return x.scaled_px.to_nchan(wins, bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`to_nchan` takes a tensor or a dicom as the input and returns multiple one channel images (the first depending on the choosen `windows` and a normalized image).  Setting `bins` to `0` only returns the windowed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(dcm.to_nchan([dicom_windows.brain], bins=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(dcm.to_nchan([dicom_windows.brain], bins=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def to_3chan(x:Tensor, win1, win2, bins=None):\n",
    "    return x.to_nchan([win1,win2],bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def to_3chan(x:DcmDataset, win1, win2, bins=None):\n",
    "    return x.scaled_px.to_3chan(win1, win2, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(dcm.to_nchan([dicom_windows.brain,dicom_windows.subdural,dicom_windows.abdomen_soft]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def save_jpg(x:Tensor|DcmDataset, path, wins, bins=None, quality=90):\n",
    "    \"Save tensor or dicom image into `jpg` format\"\n",
    "    fn = Path(path).with_suffix('.jpg')\n",
    "    x = (x.to_nchan(wins, bins)*255).byte()\n",
    "    im = Image.fromarray(x.permute(1,2,0).numpy(), mode=['RGB','CMYK'][x.shape[0]==4])\n",
    "    im.save(fn, quality=quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def to_uint16(x:Tensor|DcmDataset, bins=None):\n",
    "    \"Convert into a unit16 array\"\n",
    "    d = x.hist_scaled(bins).clamp(0,1) * 2**16\n",
    "    return d.numpy().astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def save_tif16(x:Tensor|DcmDataset, path, bins=None, compress=True):\n",
    "    \"Save tensor or dicom image into `tiff` format\"\n",
    "    fn = Path(path).with_suffix('.tif')\n",
    "    Image.fromarray(x.to_uint16(bins)).save(str(fn), compression='tiff_deflate' if compress else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axs=subplots(1,2)\n",
    "with tempfile.TemporaryDirectory() as f:\n",
    "    f = Path(f)\n",
    "    dcm.save_jpg(f/'test.jpg', [dicom_windows.brain,dicom_windows.subdural])\n",
    "    show_image(Image.open(f/'test.jpg'), ax=axs[0])\n",
    "    dcm.save_tif16(f/'test.tif')\n",
    "    show_image(Image.open(str(f/'test.tif')), ax=axs[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def set_pixels(self:DcmDataset, px):\n",
    "    self.PixelData = px.tobytes()\n",
    "    self.Rows,self.Columns = px.shape\n",
    "DcmDataset.pixel_array = property(DcmDataset.pixel_array.fget, set_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def zoom(self:DcmDataset, ratio):\n",
    "    \"Zoom image by specified ratio\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning)\n",
    "        self.set_pixels(ndimage.zoom(self.pixel_array, ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see the current size of the dicom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm.pixel_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm.zoom(7.0)\n",
    "dcm.show(); dcm.pixel_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def zoom_to(self:DcmDataset, sz):\n",
    "    \"Change image size to specified pixel size\"\n",
    "    if not isinstance(sz,(list,tuple)): sz=(sz,sz)\n",
    "    rows,cols = sz\n",
    "    self.zoom((rows/self.Rows,cols/self.Columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm.zoom_to(200); dcm.pixel_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch(as_prop=True)\n",
    "def shape(self:DcmDataset): \n",
    "    \"Returns the shape of a dicom image as rows and columns\"\n",
    "    return self.Rows,self.Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm2 = TEST_DCM.dcmread()\n",
    "dcm2.zoom_to(90)\n",
    "test_eq(dcm2.shape, (90,90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm2 = TEST_DCM.dcmread()\n",
    "dcm2.zoom(0.25)\n",
    "dcm2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _cast_dicom_special(x):\n",
    "    cls = type(x)\n",
    "    if not cls.__module__.startswith('pydicom'): return x\n",
    "    if cls.__base__ == object: return x\n",
    "    return cls.__base__(x)\n",
    "\n",
    "def _split_elem(vals):\n",
    "    res = dict()\n",
    "    for val in vals:\n",
    "        k, v = val.keyword, val.value\n",
    "        if not isinstance(v,DcmMultiValue):\n",
    "            res[k] = v\n",
    "            continue\n",
    "        res[f'Multi{k}'] = 1\n",
    "        for i,o in enumerate(v): res[f'{k}{\"\" if i==0 else i}'] = o\n",
    "    return {k: _cast_dicom_special(v) for k, v in res.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def as_dict(self:DcmDataset, px_summ=True, window=dicom_windows.brain):\n",
    "    \"Convert the header of a dicom into a dictionary\"\n",
    "    pxdata = (0x7fe0,0x0010)\n",
    "    vals = [self[o] for o in self.keys() if o != pxdata]\n",
    "    res = _split_elem(vals)\n",
    "    res['fname'] = self.filename\n",
    "    if not px_summ: return res\n",
    "    stats = 'min','max','mean','std'\n",
    "    try:\n",
    "        pxs = self.pixel_array\n",
    "        for f in stats: res['img_'+f] = getattr(pxs,f)()\n",
    "        res['img_pct_window'] = self.pct_in_window(*window)\n",
    "    except Exception as e:\n",
    "        for f in stats: res['img_'+f] = 0\n",
    "        print(res,e)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`as_dict` takes in 2 parameters: `px_summ` which by default is set to `True` and this returns additional stats such as minimal pixel value, maximum pixel value, the mean pixel value and the image standard deviation. The `window` parameter calculates the `pct_in_window` value depending on the `window` that is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm.as_dict(px_summ=True, window=dicom_windows.brain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _dcm2dict(fn, window=dicom_windows.brain, px_summ=True, **kwargs): \n",
    "    return fn.dcmread().as_dict(window=window, px_summ=px_summ, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@delegates(parallel)\n",
    "def _from_dicoms(cls, fns, n_workers=0, **kwargs):\n",
    "    return pd.DataFrame(parallel(_dcm2dict, fns, n_workers=n_workers, **kwargs))\n",
    "pd.DataFrame.from_dicoms = classmethod(_from_dicoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataframe of the values within the `header` of the dicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumothorax_source = untar_data(URLs.SIIM_SMALL)\n",
    "items = get_dicom_files(pneumothorax_source, recurse=True,  folders='train')\n",
    "dicom_dataframe = pd.DataFrame.from_dicoms(items, window=dicom_windows.brain, px_summ=True)\n",
    "dicom_dataframe.head(2).T.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DicomSegmentationDataLoaders(DataLoaders):\n",
    "    \"Basic wrapper around DICOM `DataLoaders` with factory methods for segmentation problems\"\n",
    "    @classmethod\n",
    "    @delegates(DataLoaders.from_dblock)\n",
    "    def from_label_func(cls, path, fnames, label_func, valid_pct=0.2, seed=None, codes=None, item_tfms=None, batch_tfms=None, **kwargs):\n",
    "        \"Create from list of `fnames` in `path`s with `label_func`.\"\n",
    "        dblock = DataBlock(blocks=(ImageBlock(cls=PILDicom), MaskBlock(codes=codes)),\n",
    "                           splitter=RandomSplitter(valid_pct, seed=seed),\n",
    "                           get_y=label_func,\n",
    "                           item_tfms=item_tfms,\n",
    "                           batch_tfms=batch_tfms)\n",
    "        res = cls.from_dblock(dblock, fnames, path=path, **kwargs)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.TCGA_SMALL)\n",
    "codes = np.loadtxt(path/'codes.txt', dtype=str)\n",
    "fnames = get_dicom_files(path/'dicoms')\n",
    "label_func = lambda o: path/'labels'/f'{o.stem}.png'\n",
    "\n",
    "dls = DicomSegmentationDataLoaders.from_label_func(path, fnames, label_func, codes=codes, bs=4)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
